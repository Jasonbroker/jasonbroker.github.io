  究竟如何才能充分而高效率地使用大量独立的计算设备？这个是个看似简单但却困扰了无数架构设计师的问题。
  在高性能计算机领域，这个问题确实已经解决几十年了。但是在微机以及嵌入式计算机横行的近20年，高效并行运行效率问题却越来越明显，突出。
  
  20年前，一家于苹果有着微妙关系的公司-Be公司成立了。这里做一个简介：
  
 > Be是一家成立于1990年的美国计算机公司，以其BeOS操作系统和BeBox计算机著称。Be公司由Apple前高管Jean-Louis Gassee创办，坐落在美国加利福尼亚州的Menlo Park，并在法国和日本设有下属的销售机构。早年Be公司最主要的意图在于开发一款全新的、使用C++的操作系统、并运行于其独有的硬件平台之上的操作系统。BeOS操作系统运行于BeBox计算机之上。1998年，该系统合并入Intel x86结构，并削弱了PowerPC的支持，最终在BeOS R5之后夭折。

 >BeOS：Be公司于1991年开发的一款操作系统。BeOS操作系统在很大程度上优化了数字媒体处理，并充分利用了现代硬件设备的优势，诸如利用模块化I/O带宽(modular I/O bandwidth)的对称多处理技术(symmetric multiprocessing)，普适多线程(pervasive multithreading)，抢占式多任务处理(preemptive multitasking)等。BeOS操作系统图形用户界面的开发遵循了简洁清爽的原则，API(applicatoin programming interface，应用程序编程接口)采用C++编写，兼容POSIX(Portable Operating System Interface of Unix，可移植操作系统接口)。BeOS起先被定为多媒体平台，原本可与Mac OS以及Microsoft Windows一争高下，然而最终却未能获得理想的市场份额。

> BeBox：一款Be公司推出的双处理器计算机。该计算机引人注目之处包括其CPU设定(CPU Configuration)，具备“GeekPort”的I/O带宽等。BeBox于1995年10月闪亮登场(BeBox Dual603-66)。1996年8月，处理器升级至133MHz(BeBox Dual603e-133)。1996年底该产品停产，随后BeOS操作系统合并入Macintosh。BeBox销量惨不忍睹，66MHz款售出大约1000台，而133MHz款只售出大约800台。

 BeOS操作系统最鲜明的特色在于“普适多线程(pervasive multithreading)”技术。以现在的标准来衡量，BeBox和其他运行BeOS操作系统的计算机充分利用了计算资源。BeBox的演示令人印象深刻。66MHz双处理器计算机能够流畅地运行多个视频并在后台播放CD中的很多音轨——与此同时，用户界面响应也保持一贯的流畅。BeOS操作系统让很多技术狂热者大跌眼镜，他们当中的许多人坚持认为目前的许多台式机操作体验仍旧无法与BeOS相媲美。

20世纪90年代末Apple收购了NeXT公司，而此前Apple差点就收购了Be公司。尽管普适多线程(pervasive multithreading)技术为人们带来了绝佳的操作体验，然而其在很大程度上却极端依赖于程序编写者。BeOS系统里里外外都是多线程，甚至为每一个窗口保持一个单独的线程。

对程序员来说，并行编程(parallel programming)是相当痛苦的一件事。即使最优秀的程序员，使用C或者C++这样的低级语言创建大型多线程程序时也会力不从心，时常会陷入死锁(deadlock)、或其他在执行同时多线程(multiple simultaneous threads)时可能遇到的麻烦当中。

19年前Be所面临的挑战直到现在仍在持续，虽然目前芯片上的晶体管密度和过去相比不在一个数量级之上。即使在现在的高端台式Mac上，单线程应用程序在CPU使用率为100%时，我们从CPU监视窗口中我们可以惊讶地发现，多个状态条中只有一条顶到了头而其他的几乎没有使用…

 一个CPU饱和的主线程意味着，在事件队列中，新的用户输入(user inputs)不会被应用程序终止，于是几秒钟以后就会出现这个转动的等待图标——表明程序不响应了。 这就是问题所在。目前硬件所具有的计算资源已经超越了程序员能够操控的范围，大部分计算资源实际上是处于闲置状态的。
 
 从Snow Leopard开始，OS X引入了GCD技术。我们看到GCD通过一些手段避免了当年BeOS中线程重复，线程池维护等问题，但是到底OSX 性能几何？
 
 我们知道，BeOS的设计理念是“普适多线程(pervasive multithreading)”，但是在GCD中却与BeOS理念截然相反。为了获得良好的全局响应，BeOS不惜让应用程序的每一个组件(甚至包括每一个窗口)都在其自己的线程中运行，这无疑为程序开发者增加了沉重的负担。而GCD则采用了一种更具限制性的、分级的方式：专门分配一个主程序线程用来处理所有用户事件，而(其他)工作线程用来在需要的时候执行特定的任务。换句话说，GCD不需要程序开发者来思考究竟应该如何为程序分配多个并行线程(当然GCD也会在必要的时候协助开发者进行线程的分配与优化工作)。 
 
 不管是在OSX 平台还是iOS平台，最影响用户体验的罪魁祸首就是两个字：卡顿。在OSX里面，就是彩色菊花，在iOS里面问题更严重，因为线程卡顿时用户根本不能做任何事情，只能等待任务执行完成。
 
 这在我们移动平台开发简直就是灾难性的。严重的卡顿会让用户直接删除你的应用，甚至是跑到review里面给你一个一星评价，我的天啊。
 
在通常情况下，很多普通任务是可以在瞬间完成的，但是如果在运行期间出了差错，那么就会非常耗时，阻塞主线程。

举一个例子：

在平常的情况下，用户登录操作是瞬间和服务器请求服务器也会很快返回结果。但是一个很特殊的情况是，如果该服务器出了故障，无法正常返回结果，那么该请求就会一直等待请求结果。这时候登录按钮是高亮状态的无法点击，其他操作也无法完成，程序彻底卡死。

再举一个例子：

一个应用需要上传某文件，一般情况下，文档很小，程序会在1-2秒完成上传，如果文档很大，可能需要30s甚至1分钟才行，而这期间，你几乎不能做任何事只能眼睁睁的看着他完成。
 
有了GCD这一切都变得异常简单，只需要添加两行代码把上传操作放入子线程，不需要管理全局对象， 没有线程管理，不需要额外的对象，简直方便极了。

但正是这几行线程代码，确实蕴含了非常多的门道。GCD的关键在于 dispatch_async() ，通过block实现的工作单元（unit work），将该单元嵌入在原来普通的代码中，不需要额外的重构。

但是，GCD中非常令人关注的问题是，该工作单元中的任务完成后是如何检测到的？此时GCD的设计理念：以主线程为中心就起到了重要作用：在异步（子）线程中可以简单的将block内部代码放回主线程中，更新UI；这种方式，非常明显的好处是简单高效。

对于Grand Central Dispatch，Apple的一个口号是：“并行”海洋中的“串行”岛屿(islands of serialization in a sea of concurrency)。而正是这些“串行岛屿”将开发者从同步数据访问(simulaneous data access)、死锁(deadlock)等多线程处理时经常遇到的棘手问题中解脱出来(译注：详情请参考developer.apple.com)。GCD倡导程序员从程序中识别出那些可以在主线程上更好执行的函数，并能够轻松地在保持子任务之间现有的次序及独立性的基础上将整个工作单元分离出来。
 
对于GCD，我们需要明确的是他不是一个新的Cocoa框架或者类似的东西，而是一个嵌入操作系统最底层的C语言库。GCD构建在libSystem内，整合了libC以及其他一些userspace底层的代码。

##队列与线程

GCD构建于几个简单的实体之上。

###队列(queue）
在队列的FIFO(First in, First out)顺序中，任务首先入队列(enqueue)，然后出队列(dequeue)。出队列(dequeue)意味着该任务被传递至线程并执行。

尽管GCD队列会按照FIFO顺序将任务传递至线程，然而许多来自同一队列的任务仍然有可能在任何给定的时间内并行运行。尽管出队列的顺序由FIFO决定，然而任务的完成顺序却不一定如此。但是首先，我们来看一看另外一种队列。一个串行队列(serial queue)运行起来和普通队列一样，但是其每次只能运行一个任务，这就意味着一系列任务完成的顺序将和FIFO顺序一致。对串行队列来说，每一个应用程序拥有一个绝对的“主队列”，即运行于主线程上的主队列。，线程可以根据需要而增加，并且在运行结束之后释放空闲的线程。这就是GCD的一个重要特色，能够根据应用程序的实际需要调整线程数量，提高工作效率。以传统的手工方式管理线程，最困难的部分莫过于，究竟需要创建多少个线程才能使性能最大化。

来举一个例子。譬如一个程序可以被分割成八个独立的工作模块，而该程序在一个八核计算机上创建了四个线程，是否能够简单地说这个程序创建了过多或者过少的线程了呢？这是个有趣的问题。答案的关键在于，与系统中正在执行的其他工作有关。

如果这八个核中的六个核已为其他的一些工作所占用(所饱和)，那么创建四个线程则意味着操作系统将周旋于这四个线程并浪费了不少时间，尽管这里有两个空闲的内核。但是如果先前在执行的其他工作完成了，那么这时候实际上就有八个空闲的内核而只有四个线程，使将近一半系统资源闲置。

除了一些极其特殊的程序之外，程序员无法事先知道究竟需要创建多少线程。对于特定的计算机来说，有多少内核正在使用？如果有更多的核进入闲置状态，那么程序又如何得知并适时调整以使用这些闲置的资源？

底线在于，在任意给定时间，最优化的线程数目通过一个单一的、全局的实体来确定。在Snow Leopard中，这个实体就是GCD。如果没有队列运行那么GCD将保持零线程；一旦有任务出队列，GCD将创建新的线程优化硬件资源的使用。GCD知道系统拥有多少内核，也知道当前执行的任务究竟需要多少线程。当一个队列中的任务执行结束并不再需要线程时，GCD会调配线程至其他出队列并即将运行的任务。

另外，这里还存在更为深入的优化。在Mac OS X中，线程实际上是相对重要的(heavyweight)。每一个线程维持其自身的一系列注册值(register value)，堆栈指针(stack pointer)程序计算器(program counter)，用来追踪其安全凭证(security credentials)的内核数据结构(kernel data structures)，调度优先级(scheduling priority)，等等。这就意味着，每个线程本身就会有超过512KB的系统资源开销。设想一下，如果创建一千个线程，就会耗用大概半GB的内存和内核资源，更不要提线程中的具体数据了。

而队列本身是相对不那么重要的(lightweight)，开发者可以根据需要随意创建，一百个甚至一千个都没问题。例如在一个队列中被分配了两个线程用来运行其三个任务，在其中一个线程上执行了两个任务。线程不仅在内存开销上是heavyweight的，创建线程本身也会耗费一定的系统资源。为每一个任务创建一个新的线程显然是最糟糕的选择。而GCD能够合理调配使每一个线程执行多个任务，就整个系统而言，这本身就是非常高校的。

通过GCD，我们在上面提到的一个问题迎刃而解——程序员不必纠结于究竟应该创建多少个线程，而是应该集中精力来优化并行算法。如果程序需要500个并行任务，那么程序员可以创建500个GCD队列并在其中分配自己的工作，然后GCD会根据具体需要创建线程。而且，线程数目会根据系统实际状况进行动态调整。

不得不指出很重要的一点，由于新推出的计算机往往配备了越来越多的CPU内核，或许程序员根本不必改动他们的程序。GCD将自然地应用一切可用的计算资源，以满足程序员最初创建的队列数目并实现最优化并行运行。

而且，GCD队列可以在任意复杂的有向非循环图(directed acyclic graph)中安排和调配。队列层次(queue hierarchied)结构可以用来将来自不同的子系统中的任务导入一系列中央控制队列中，或者迫使一系列普通队列成为一个串行队列，从而有效地间接串行化。
具体内容请查阅http://en.wikipedia.org/wiki/Directed_acyclic_graph

同时，队列优先级有几个不同的级别，规定了线程被分配的频率和紧要程度。线程可以被中止，恢复或者取消。线程也可以被分组归类，允许所分配到该组的任务都能够作为一个单元被跟踪。所以说，GCD通过队列和线程形成了一种简洁而又极为实用的逻辑结构。

关于GCD的内部实现细节，将在GCD的内部实现中进行详细讨论。

 
 
 
 
 
 
 